<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>资源调度-Pod调度策略详解 &mdash; 运维开发修炼之路</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="优先级与抢占式调度" href="5.%E4%BC%98%E5%85%88%E7%BA%A7%E4%B8%8E%E6%8A%A2%E5%8D%A0%E5%BC%8F%E8%B0%83%E5%BA%A6.html" />
    <link rel="prev" title="资源管理-标签、选择器及注解" href="3.%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-%E6%A0%87%E7%AD%BE%E3%80%81%E9%80%89%E6%8B%A9%E5%99%A8%E5%8F%8A%E6%B3%A8%E8%A7%A3.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> 小健_Docker_K8s_Blog
            <img src="../../_static/docker-k8s.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../01.Docker%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E6%88%983%E7%89%88/index.html">01.Docker技术入门与实战3版</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../02.Kubernetes%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97/index.html">02.Kubernetes实战指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../03.Docker%E7%BB%8F%E5%85%B8%E5%AE%9E%E4%BE%8B/index.html">03.Docker经典实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../04.Prometheus%E7%9B%91%E6%8E%A7%E8%BF%90%E7%BB%B4%E5%AE%9E%E6%88%98/index.html">04.Prometheus监控运维实战</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">05.Kubernetes入门到实践</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../1.%E5%AE%B9%E5%99%A8%E7%9A%84%E5%8F%91%E5%B1%95%E5%8F%B2/index.html">1.容器的发展史</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2.Kubernetes%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/index.html">2.Kubernetes的核心概念</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3.Kubernetes%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2/index.html">3.Kubernetes的安装和部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4.Pod/index.html">4.Pod的基本操作</a></li>
<li class="toctree-l2"><a class="reference internal" href="../5.%E6%8E%A7%E5%88%B6%E5%99%A8/index.html">5.控制器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../6.Service%E5%92%8CIngress/index.html">6.Service和Ingress</a></li>
<li class="toctree-l2"><a class="reference internal" href="../7.%E5%AD%98%E5%82%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/index.html">7.存储与配置</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">8.Kubernetes资源的管理及调度</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="1.%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6-%E4%B8%BAPod%E8%AE%BE%E7%BD%AE%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90.html">资源调度-为Pod设置计算资源</a></li>
<li class="toctree-l3"><a class="reference internal" href="2.%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4.html">资源管理-命名空间</a></li>
<li class="toctree-l3"><a class="reference internal" href="3.%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-%E6%A0%87%E7%AD%BE%E3%80%81%E9%80%89%E6%8B%A9%E5%99%A8%E5%8F%8A%E6%B3%A8%E8%A7%A3.html">资源管理-标签、选择器及注解</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">资源调度-Pod调度策略详解</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">1. 调度过程</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">2. 节点选择调度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">3. 节点亲和性调度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">4. Pod亲和性与反亲和性调度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11">5. 污点与容忍度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="5.%E4%BC%98%E5%85%88%E7%BA%A7%E4%B8%8E%E6%8A%A2%E5%8D%A0%E5%BC%8F%E8%B0%83%E5%BA%A6.html">优先级与抢占式调度</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../9.API-Server/index.html">9.API-Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10.Kubernetes%E7%9A%84%E6%89%A9%E5%B1%95/index.html">10.Kubernetes的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../11.%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E6%A1%88%E4%BE%8B/index.html">11.项目部署案例</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">小健_Docker_K8s_Blog</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">05.Kubernetes入门到实践</a> &raquo;</li>
          <li><a href="index.html">8.Kubernetes资源的管理及调度</a> &raquo;</li>
      <li>资源调度-Pod调度策略详解</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/05.Kubernetes入门到实践/8.Kubernetes资源的管理及调度/4.资源调度-Pod调度策略详解.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#pod" id="id14">资源调度-Pod调度策略详解</a></p>
<ul>
<li><p><a class="reference internal" href="#id1" id="id15">1. 调度过程</a></p>
<ul>
<li><p><a class="reference internal" href="#id2" id="id16">1. 预选阶段</a></p></li>
<li><p><a class="reference internal" href="#id3" id="id17">2. 优选阶段</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id4" id="id18">2. 节点选择调度</a></p></li>
<li><p><a class="reference internal" href="#id5" id="id19">3. 节点亲和性调度</a></p>
<ul>
<li><p><a class="reference internal" href="#id6" id="id20">3.1 为节点设置标签</a></p></li>
<li><p><a class="reference internal" href="#id7" id="id21">3.2 亲和性调度</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id8" id="id22">4. Pod亲和性与反亲和性调度</a></p>
<ul>
<li><p><a class="reference internal" href="#id9" id="id23">4.1 Pod亲和性调度</a></p></li>
<li><p><a class="reference internal" href="#id10" id="id24">4.2 Pod反亲和性调度</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#id11" id="id25">5. 污点与容忍度</a></p>
<ul>
<li><p><a class="reference internal" href="#id12" id="id26">5.1 污点</a></p></li>
<li><p><a class="reference internal" href="#id13" id="id27">5.2 容忍</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<section id="pod">
<h1><a class="toc-backref" href="#id14">资源调度-Pod调度策略详解</a><a class="headerlink" href="#pod" title="Permalink to this headline">¶</a></h1>
<p>Pod的调度是由kube-scheduler组件来控制的，我们可以称该组件为调度器。</p>
<p>所有Pod都需要经过调度器才能分配到具体的Node上。</p>
<p>调度器用于监听要求创建或还未分配Node的Pod资源，为Pod自动分配相应的Node。</p>
<p>kube-scheduler在调度时会考虑各种因素，包括资源需求、硬件/软件/指定限制条件、内部负载情况等。</p>
<p>kube-scheduler所执行的各项操作是基于API Server的，如调度器会通过API
Server的Watch接口监听新建Pod，搜索所有满足Pod需求的Node列表，再执行Pod调度逻辑，找到适合运行这个Pod的最佳Node。</p>
<p>调度成功后会将Pod绑定到目标Node上。</p>
<p>如果没有找到合适的Node，Pod将保持Pending状态，不会分配到任何节点上，直到集群情况发生变化且满足条件为止。</p>
<section id="id1">
<h2><a class="toc-backref" href="#id15">1. 调度过程</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>kube-scheduler将按以下3个步骤进行调度。</p>
<p>（1）预选——在所有节点中，调度器用一组规则过滤掉不符合要求的节点。例如，Pod指定了resource.requests.cpu或memory，因此可用资源比Pod需求资源量少的主机会被筛除。</p>
<p>（2）优选——在选择出符合要求的候选节点后，用一组规则对这些节点的优先级打分。比如，优先把一个Deployment控制器Pod分配到不同的主机上，优先使用负载最低的主机等。</p>
<p>（3）绑定——选择打分最高的节点执行绑定操作。如果最高得分中有好几个节点，则会从中随机选择一个节点。</p>
<p>调度过程</p>
<img alt="../../_images/image-20220419155639011.png" src="../../_images/image-20220419155639011.png" />
<section id="id2">
<h3><a class="toc-backref" href="#id16">1. 预选阶段</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>预选阶段的默认调度策略如下，主要分为3类。</p>
<ul class="simple">
<li><p>资源性预选策略。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- PodFitsResources：检查主机上的空闲资源是否满足Pod中容器的resource. requests.cpu或memory。
- PodFitsHostPorts：检查Pod中容器的hostPort属性所指定的端口是否已被节点上其他容器或服务占用。
- CheckNodeMemoryPressure：判断节点是否已经进入内存压力状态。如果进入，则只允许调度内存标记为0的Pod。
- CheckNodePIDPressure：检查节点是否存在进程ID资源紧缺情况。
- CheckNodeDiskPressure：判断节点是否已进入存储压力状态（文件系统磁盘已满或接近满）。
- CheckNodeCondition：检查节点网络是否可用，或者kubelet组件是否就绪。
</pre></div>
</div>
<ul class="simple">
<li><p>指定性预选策略。这种预选方式更多是用户主动选择的，需要用户来指定与设置。稍后将详细讲解这种预选方式。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- PodFitsHost：如果Pod设置了 spec.nodeName，则只有名字相匹配的节点才能运行Pod。


- PodMatchNodeSelector：如果Pod设置了spec.nodeSelector，则只有标签与之匹配的节点才能运行Pod。如果Pod设置了
                  spec.affinity.nodeAffinity. requiredDuringScheduling属性，检查是否与节点的亲和性要求相匹配。

- MatchInterPodAffinity：如果Pod设置了spec.affinity.podAffinity. requiredDuringScheduling或
         spec.affinity.podAntiAffinity. requiredDuringScheduling属性，检查是否与Pod的亲和性/反亲和性要求相匹配。

- PodToleratesNodeTaints：如果Pod通过spec.tolerations属性设置了容忍度（tolerate），且其容忍度的effect属性为                NoSchedule或NoExecute，则检查Pod是否能容忍节点上的污点（taint）。
</pre></div>
</div>
<ul class="simple">
<li><p>存储卷预选策略。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- CheckVolumeBinding：检查Pod是否能适配到它所请求的存储卷，该规则对已绑定或未绑定PV的PVC都起作用。

- NoDiskConflict：检查Pod所需的卷是否和节点已存在的卷冲突。如果这个主机已经挂载了卷，同样使用这个卷的其他Pod不能调度到这个            主机上，仅限于GCE PD、AWS EBS、Ceph RBD以及iSCSI。

- NoVolumeZoneConflict：在给定区域限制前提下，检查在此主机上部署的 Pod 是否存在卷冲突（前提是存储卷设有区域调度约束）。
         MaxCSI/MaxEBS/MaxGCEPD/MaxAzureDisk/MaxCinderVolumeCount：检查需要挂载的相关存储卷是否已超过配置限制。
</pre></div>
</div>
</section>
<section id="id3">
<h3><a class="toc-backref" href="#id17">2. 优选阶段</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>优选阶段的默认调度策略主要分4类。</p>
<ul class="simple">
<li><p>资源性优选策略。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>LeastRequestedPriority：计算Pod需要的CPU和内存在当前节点可用资
                        源上的百分比。具有最小百分比的节点最优，根据公式cpu((capacity–
                        sum(requested))*10/capacity)+memory((capacity–
                        sum(requested))* 10/capacity)/2计算得分。

BalancedResourceAllocation：该调度策略出于平衡度考虑，避免出
                            现CPU、内存消耗不均匀的情况。优先选择在部署Pod后各项资源更均衡的机
                            器。得分计算公式为10 –
                            abs(totalCpu/cpuNodeCapacity−totalMemory/memoryNodeCapacity)*10。


ResourceLimitsPriority：优先选择满足Pod中容器的resource.limits.cpu或memory的节点。
</pre></div>
</div>
<ul class="simple">
<li><p>容灾性优选策略。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>SelectorSpreadPriority：为了更好地容灾，优先减少节点上属于同一
                        个Service或控制器的Pod数量。同一个Service或控制器的Pod数量越少，得分越高。

ImageLocalityPriority：尽量将使用大镜像的容器调度到已经下拉了该镜像的节点上。默认未启用该策略。若不存在所需镜像，返回0分；                        若存在镜像，镜像越大，得分越高。
</pre></div>
</div>
<ul class="simple">
<li><p>指定性优选策略。这种优选方式更多是用户主动选择的，需要用户进行指定与设置。稍后将详细讲解这种优选方式。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NodeAffinityPriority：如果Pod设置了
                    spec.affinity.nodeAffinity. preferredDuringScheduling属
                    性，优先选择最大限度满足该亲和性条件的节点。


InterPodAffinityPriority：如果Pod设置了
                        spec.affinity.podAffinity. preferredDuringScheduling或
                        spec.affinity.podAntiAffinity.
                        preferredDuringScheduling属性，优先选择最大限度满足该亲和性/
                        反亲和性条件的节点。

TaintTolerationPriority：如果Pod通过spec.tolerations属性设
                        置了容忍度，且其容忍度的effect属性为PreferNoSchedule，则优先选
                        择Pod匹配污点最少的节点。污点配对成功的项越多，得分越低。
</pre></div>
</div>
<ul class="simple">
<li><p>特殊优选策略（通常只用于测试或特殊场景）</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>NodePreferAvoidPodsPriority：如果设置了节点的注解，
                        scheduler.alpha. Kubernetes. io/preferAvoidPods =
                        &quot;...&quot;，则由 ReplicationController（以及基于它的Deployment控制器）
                        控制的Pod在这个节点上忽视所有其他优选策略，该节点拥有所有节点中最低的调度优先级。


MostRequestedPriority：在使用率最高的主机节点上优先调度Pod。一般用在缩减集群时，通过这种方式可以腾出空闲机器。默认未启用该                       策略。EqualPriorityMap：将所有节点设置为相同的优先级。默认未启用该策略。
</pre></div>
</div>
<p>Kubernetes提供了调度策略的定义，可以在kube-scheduler启动参数中添加–policy-
config-fileAaaaaaaaaaAAzaz来指定要运用的调度配置文件。配置文件的格式如下所示。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;kind&quot;</span> <span class="p">:</span> <span class="s2">&quot;Policy&quot;</span><span class="p">,</span>
<span class="s2">&quot;apiVersion&quot;</span> <span class="p">:</span> <span class="s2">&quot;v1&quot;</span><span class="p">,</span>
<span class="s2">&quot;predicates&quot;</span> <span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;PodFitsResources&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;PodFitsHostPorts&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;CheckNodeMemoryPressure&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;NoDiskConflict&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;PodFitsHost&quot;</span><span class="p">},</span>
    <span class="o">......</span>
<span class="p">],</span>
<span class="s2">&quot;priorities&quot;</span> <span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;LeastRequestedPriority&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;SelectorSpreadPriority&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;NodeAffinityPriority&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;NodePreferAvoidPodsPriority&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="o">......</span>
<span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Kubernetes非常灵活，还可以自己定义新的预选和优选策略并添加到原有配置中，甚至可以重新编写自定义的调度器，替代默认调度器或与默认调度器共同使用。之前介绍各个调度策略时，提到了指定性预选和优选策略。这些方式更多是用户主动选择的，需要用户指定与设置。</p>
</section>
</section>
<section id="id4">
<h2><a class="toc-backref" href="#id18">2. 节点选择调度</a><a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>在某些时候，可能需要指定将Pod部署在某台Node上。此时就可以使用spec.nodeName直接指定Pod需要调度到的具体机器（通过PodFitsHost预选策略）。例如，以下Pod模板。</p>
<p><code class="docutils literal notranslate"><span class="pre">templateNodeschudeing.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">examplepodforhostname</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">examplepod-container</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">busybox</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
    <span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;sh&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;-c&#39;</span><span class="p p-Indicator">]</span>
    <span class="nt">args</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;echo</span><span class="nv"> </span><span class="s">&quot;Hello</span><span class="nv"> </span><span class="s">Kubernetes!&quot;;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">3600&#39;</span><span class="p p-Indicator">]</span>
  <span class="nt">nodeName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gitee-k8s-w29</span>
</pre></div>
</div>
<p>应用模板后，Pod将直接调度到gitee-k8s-w29上</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f templateNodeschudeing.yml
$ kubectl get pod -o wide
NAME                    READY   STATUS              RESTARTS   AGE         IP       NODE            NOMINATED NODE   READINESS GATES
examplepodforhostname   <span class="m">0</span>/1     ContainerCreating   <span class="m">0</span>          &lt;invalid&gt;   &lt;none&gt;   gitee-k8s-w29   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
</section>
<section id="id5">
<h2><a class="toc-backref" href="#id19">3. 节点亲和性调度</a><a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>点亲和性调度表示会根据节点的标签挑选合适的节点。
由于节点亲和性调度策略依赖于节点的标签，因此首先需要为节点设置标签。</p>
<section id="id6">
<h3><a class="toc-backref" href="#id20">3.1 为节点设置标签</a><a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>要给各个节点设置标签，命令如下</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl label nodes <span class="o">{</span>node名称<span class="o">}</span> <span class="o">{</span>标签名<span class="o">}={</span>标签值<span class="o">}</span>
</pre></div>
</div>
<p>例如以下命令。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl label nodes gitee-k8s-w29 <span class="nv">disktype</span><span class="o">=</span>ssd
</pre></div>
</div>
<p>使用以下命令可以删除定义的标签。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl label nodes gitee-k8s-w29 disktype-
</pre></div>
</div>
<p>设置完成后可以通过<code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">kubectl</span> <span class="pre">describe</span> <span class="pre">node</span> <span class="pre">gitee-k8s-w29</span></code>命令查看标签配置情况</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl describe node gitee-k8s-w29
Name:               gitee-k8s-w29
Roles:              &lt;none&gt;
Labels:             beta.kubernetes.io/arch<span class="o">=</span>amd64
                    beta.kubernetes.io/os<span class="o">=</span>linux
                    <span class="nv">disktype</span><span class="o">=</span>ssd
                    kubernetes.io/arch<span class="o">=</span>amd64
                    kubernetes.io/hostname<span class="o">=</span>gitee-k8s-w29
                    kubernetes.io/os<span class="o">=</span>linux
</pre></div>
</div>
<p>除了自己定义的标签之外，Kubernetes还会为每个节点自动生成系统级标签。</p>
<ul class="simple">
<li><p>Kubernetes.io/hostname：机器名称，例如，gitee-k8s-w29。</p></li>
<li><p>Kubernetes.io/os：系统名称，例如，Linux/Windows。</p></li>
<li><p>Kubernetes.io/arch：架构名称，例如，amd64。</p></li>
</ul>
<p>只有使用公有云厂商自家的Kubernetes时才会有以下标签，私有Kubernetes集群没有这些标签。</p>
<ul class="simple">
<li><p>failure-domain.beta.Kubernetes.io/region：地域名称。</p></li>
<li><p>failure-domain.beta.Kubernetes.io/zone：地域下的区域名称。</p></li>
<li><p>beta.Kubernetes.io/instance-type：使用的cloudprovider名称。</p></li>
</ul>
</section>
<section id="id7">
<h3><a class="toc-backref" href="#id21">3.2 亲和性调度</a><a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>在某些时候，可能需要将Pod调度到指定类型的节点中。</p>
<p>通过spec.nodeSelector或spec.affinity.nodeAffinity.requiredDuringScheduling可以将Pod调度
到拥有指定标签的节点上（通过PodMatchNodeSelector预选策略），这种方式属于硬亲和性调度，是强制性的，节点不允许调度到不符合条件的机器上。</p>
<p>为了看看如何通过spec.nodeSelector将Pod调度到有指定标签的节点上，首先，创建以下模板。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl label nodes gitee-k8s-w29 <span class="nv">disktype</span><span class="o">=</span>ssd
$ kubectl label nodes gitee-k8s-w29 <span class="nv">env</span><span class="o">=</span>prd
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">example-scheduingv1.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">examplefornodeselector</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
  <span class="nt">nodeSelector</span><span class="p">:</span>
    <span class="nt">disktype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ssd</span>
    <span class="nt">env</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">prd</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ kubectl apply -f example-scheduingv1.yml
$ kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE            NOMINATED NODE   READINESS GATES
examplefornodeselector   <span class="m">1</span>/1     Running   <span class="m">0</span>          93s   <span class="m">10</span>.0.24.101   gitee-k8s-w29   &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
<p>除了spec.nodeSelector之外，还可以通过spec.affinity.nodeAffinity.requiredDuringScheduling
将 Pod
调度到有指定标签的节点上。它们的主要区别在于，spec.affinity.nodeAffinity.requiredDuringScheduling可以设置更复杂的表达式。</p>
<p>例如，之前提到的In、NotIn、Exists、DoesNotExist等属性。</p>
<p>requiredDuringScheduling有两种用法，</p>
<p>一种是requiredDuringScheduling RequiredDuringExecution，</p>
<p>另一种是requiredDuringSchedulingIgnored DuringExecution。</p>
<p>两者都可以将Pod调度到存在指定标签的节点上，但区别在于，前者Pod调度成功运行后，如果节点标
签发生变化而不再满足条件，Pod将会被驱逐出节点，而后者仍会在节点上运行。</p>
<p>还可以通过spec.affinity.nodeAffinity.preferredDuringScheduling属性来指定节点标签，优先选择最大限度满足该亲和性条件的节点（通过NodeAffinityPriority优选策略）。这种方式属于软亲和性调度，是非强制性的。节点根据优先级的得分情况可能会也可能不会调度到不符合条件的机器上。</p>
<p>为了创建有亲和性条件的Pod，首先，创建以下模板。</p>
<p><code class="docutils literal notranslate"><span class="pre">examplefornodeaffinity.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">examplefornodeaffinity</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="nt">nodeAffinity</span><span class="p">:</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
        <span class="nt">nodeSelectorTerms</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">env</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">prd</span><span class="p p-Indicator">]}</span>
          <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">cpu</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">NotIn</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">4core</span><span class="p p-Indicator">]}</span>
      <span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
        <span class="nt">preference</span><span class="p">:</span>
          <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">disktype</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">ssd</span><span class="p p-Indicator">,</span><span class="nv">flash</span><span class="p p-Indicator">]}</span>
</pre></div>
</div>
<p>这里我们<strong>通过nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution设置了硬亲和性条件，寻找env标签取值在prd内，cpu标签取值不在4core内的节点。</strong></p>
<p><strong>然后通过nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution设置软亲和性条件，优先寻找disktype在ssd/flash内的节点。</strong></p>
<p>其中，weight字段表示相对于其他软亲和性条件的优先级比值，取值范围为
1～100，因为目前我们只 设置了一个软亲和性条件，所以填写任意值均可。</p>
<p>应用该模板后，其调度过程将如图所示。k8snode1 的标签由于不符合required
DuringScheduling条件，在预选阶段就会被筛除。然后对k8snode2和k8snode3进行优先级选择，根据preferredDuringScheduling的设置，k8snode3满足这个条件，因此将获得最高优先级，Pod调度到k8snode3上的概率更大。</p>
<p>调度过程</p>
<img alt="../../_images/image-20220419180503523.png" src="../../_images/image-20220419180503523.png" />
</section>
</section>
<section id="id8">
<h2><a class="toc-backref" href="#id22">4. Pod亲和性与反亲和性调度</a><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<section id="id9">
<h3><a class="toc-backref" href="#id23">4.1 Pod亲和性调度</a><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p><strong>有些时候，需要将某些Pod与正在运行的已具有某些特质的Pod调度到一起，因此就需要使用Pod亲和性调度方式。</strong></p>
<p>通过spec.affinity.podAffinity.requiredDuringScheduling可将Pod调度到带有指定标签的Pod节点上（通过MatchInterPodAffinity预选策略）。</p>
<p>requiredDuring Scheduling有两种用法</p>
<ul class="simple">
<li><p>requiredDuringSchedulingRequiredDuringExecution，</p></li>
<li><p>requiredDuringSchedulingIgnoredDuringExecution。</p></li>
</ul>
<p>两者都可以将Pod调度到存在指定标签的Pod节点上，区别在于，前者Pod调度成功运行后，如果节点上已
有Pod的标签发生变化且不再满足条件，Pod将会被驱逐出节点，而后者仍会在节点上运行。</p>
<p>另外，还可以通过spec.affinity.podAffinity.preferredDuringScheduling属性来指定节
点上 Pod 的标签，优先选择最大限度满足该亲和性条件的节点（通过
InterPodAffinityPriority优选策略）。这种方式属于软亲和性调度，是非强制性的。</p>
<p>节点根据优先级得分情况，可能会也可能不会调度到不符合条件的机器上。</p>
<p>假设现在各个机器上Pod的标签情况如图所示。appType: Log
表示它是一个收集系统日志的应用，appType:
SystemClean表示它是一个定期清理系统垃圾的应用。</p>
<p>各个机器上的Pod标签</p>
<img alt="../../_images/image-20220420100144485.png" src="../../_images/image-20220420100144485.png" />
<p>现在我们需要创建一个Pod，如果它会和系统交互并产生影响，就必须和能收集系统日志的Pod部署到一起。因为读Pod也会生成一定数量的系统垃圾，所以需要优先和能定期清理垃圾的Pod部署在一起。</p>
<p>为了创建具有Pod亲和性条件的Pod，创建以下模板。</p>
<p><code class="docutils literal notranslate"><span class="pre">exampleforpodaffinity.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">exampleforpodaffinity</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="c1"># pod亲和性</span>
    <span class="nt">podAffinity</span><span class="p">:</span>
      <span class="c1"># 硬亲和性条件</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">labelSelector</span><span class="p">:</span>
          <span class="nt">matchExpressions</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">appType</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">Log</span><span class="p p-Indicator">]}</span>
        <span class="nt">topologyKey</span><span class="p">:</span> <span class="s">&#39;Kubernetes.io/hostname&#39;</span>
      <span class="c1"># 软亲和性条件</span>
      <span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
        <span class="nt">podAffinityTerm</span><span class="p">:</span>
          <span class="nt">labelSelector</span><span class="p">:</span>
            <span class="nt">matchExpressions</span><span class="p">:</span>
              <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">appType</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">SystemClean</span><span class="p p-Indicator">]}</span>
          <span class="nt">topologyKey</span><span class="p">:</span> <span class="s">&#39;Kubernetes.io/hostname&#39;</span>
</pre></div>
</div>
<p>这里通过podAffinity.requiredDuringSchedulingIgnoredDuringExecution设置了硬亲和性条件，寻找appType标签取值在Log内的Pod。</p>
<p>然后通过nodeAffinity.
preferredDuringSchedulingIgnoredDuringExecution设置了软亲和性条件，优先寻找appType在SystemClean内的Pod。</p>
<p>其中，weight字段表示相对于其他软亲和性条件的优先级比例，取值范围为1～100。因为目前我们只设置了一个软亲和性条件，所以填写任意值均可。</p>
<p>值得注意的是，对于Pod亲和性，无论是硬亲和性还是软亲和性都设置了topologyKey属性，把该属性设置为节点的标签名称。</p>
<p>如果满足Pod亲和性条件，则将Pod调度到和已有 Pod
的所在节点拥有相同节点标签的机器上。</p>
<p>这里使用了系统标签Kubernetes.io/
hostname（主机名称），它表示如果满足亲和性条件，则会
将Pod调度到和已有Pod所在节点的Kubernetes.io/hostname标签值相同的节点上。</p>
<p>换句话说，会将该Pod调度到同一台机器上。</p>
<p>也可以将topologyKey设置为之前示例中使用的disktype节点标签等，如果满足亲和性条件，就会将Pod调度到与
disktype一致的节点上，但这些节点也可能有多个。</p>
<p>应用该模板后，其调度过程将如下图 所示。</p>
<p>k8snode3 的标签由于不符合required
DuringScheduling条件，因此在预选阶段就会被筛除。</p>
<p>然后对k8snode1和k8snode2进行优先级选择，根据preferredDuringScheduling的设置，k8snode2满足这个条件，因此将获得最高优先级，Pod调度到k8snode2上的概率更大。</p>
<p>调度过程</p>
<img alt="../../_images/image-20220420101531071.png" src="../../_images/image-20220420101531071.png" />
</section>
<section id="id10">
<h3><a class="toc-backref" href="#id24">4.2 Pod反亲和性调度</a><a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>当不能将某些Pod与正在运行的已具有某些特质的Pod调度到一起时，就需要使用Pod反亲和性调度方式。</p>
<p>Pod反亲和性调度和Pod亲和性调度的作用恰恰相反。</p>
<p>Pod反亲和性使用podAntiAffinity属性来定义，而在podAntiAffinity内部，其子属性定义方式和podAffinity一模一样。</p>
<p>假设现在各个机器上Pod的标签情况如图所示。</p>
<p>security: level3表示它是一个安全级别非常高的应用，appType:
BigdataCaculate表示它是大数据计
算应用，可能会随时消耗全部的CPU或内存资源。</p>
<p>各个机器上的Pod标签</p>
<img alt="../../_images/image-20220420101741633.png" src="../../_images/image-20220420101741633.png" />
<p>现在我们需要创建一个Pod。假设由于公司政策，其他任何Pod都不允许和安全等级高于3的应用部署到一起。</p>
<p>而因为大数据应用太消耗节点的CPU或内存资源，所以不推荐与它们部署在一起。</p>
<p>为了创建具有Pod反亲和性条件的Pod，创建以下模板。</p>
<p><code class="docutils literal notranslate"><span class="pre">exampleforpodantiaffinity.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">exampleforpodantiaffinity</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
  <span class="nt">affinity</span><span class="p">:</span>
    <span class="c1"># pod反亲和性</span>
    <span class="nt">podAntiAffinity</span><span class="p">:</span>
      <span class="c1"># 硬反亲和性条件</span>
      <span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">labelSelector</span><span class="p">:</span>
        <span class="nt">matchExpressions</span><span class="p">:</span>
          <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">security</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">level3</span><span class="p p-Indicator">]}</span>
        <span class="nt">topologyKey</span><span class="p">:</span> <span class="s">&#39;Kubernetes.io/hostname&#39;</span>
      <span class="c1"># 软反亲和性条件</span>
      <span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
        <span class="nt">podAffinityTerm</span><span class="p">:</span>
          <span class="nt">labelSelector</span><span class="p">:</span>
            <span class="nt">matchExpressions</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="p p-Indicator">{</span><span class="nt">key</span><span class="p">:</span> <span class="nv">appType</span><span class="p p-Indicator">,</span><span class="nt"> operator</span><span class="p">:</span> <span class="nv">In</span><span class="p p-Indicator">,</span><span class="nt"> values</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">BigdataCaculate</span><span class="p p-Indicator">]}</span>
          <span class="nt">topologyKey</span><span class="p">:</span> <span class="s">&#39;Kubernetes.io/hostname&#39;</span>
</pre></div>
</div>
<p>应用该模板后，其调度过程将如下图所示。k8snode2 的标签因为满足required
DuringScheduling的反亲和条件，所以在预选阶段就会被筛除。</p>
<p>然后对k8snode1和k8snode3进行优先级选择，根据preferredDuringScheduling的设置，k8snode3不满足反亲和条件，因此它将获得最高优先级，Pod调度到k8snode3上的概率更大。</p>
<p>调度过程</p>
<img alt="../../_images/image-20220420102727547.png" src="../../_images/image-20220420102727547.png" />
<p><strong>注意：在Pod亲和性与反亲和性调度过程中会涉及大量调度运算，这会显著减慢在大型集群中的调度。不建议在大于几百个节点的集群中使用它们。</strong></p>
</section>
</section>
<section id="id11">
<h2><a class="toc-backref" href="#id25">5. 污点与容忍度</a><a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<section id="id12">
<h3><a class="toc-backref" href="#id26">5.1 污点</a><a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>顾名思义，污点表示一个节点上存在不良状况。污点会影响Pod的调度，其定义方式如下。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ kubectl taint node {节点名称} {污点名称}={污点值}:{污点的影响}
</pre></div>
</div>
<p>污点名称及污点值类似于标签，也是一种键值对形式。污点的影响一共有3种。</p>
<ul class="simple">
<li><p>NoExecute：不将Pod调度到具备该污点的机器上。如果Pod已经在某台机器上运行，且设置了NoExecute污点，则不能容忍该污点的Pod将会被驱逐。</p></li>
<li><p>NoSchedule：不将Pod调度到具备该污点的机器上。对于已运行的Pod不会驱逐。</p></li>
<li><p>PreferNoSchedule：不推荐将Pod调度到具备该污点的机器上。</p></li>
</ul>
<p>前两种影响会触发
PodToleratesNodeTaints预选策略，最后一种影响会触发TaintTolerationPriority优选策略。</p>
<p>例如，可以给其中一台机器添加污点。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl taint node gitee-k8s-w29 <span class="nv">restart</span><span class="o">=</span>hourly:NoSchedule
</pre></div>
</div>
<p>可以通过以下命令删除污点。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl taint node gitee-k8s-w29 restart:NoSchedule-
</pre></div>
</div>
<p>设置完成后可以通过<code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">kubectl</span> <span class="pre">describe</span> <span class="pre">node</span> <span class="pre">gitee-k8s-w29</span></code>命令查看污点配置情况。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ kubectl describe node gitee-k8s-w29
Name:               gitee-k8s-w29
Roles:              &lt;none&gt;
Labels:             beta.kubernetes.io/arch<span class="o">=</span>amd64
                    beta.kubernetes.io/os<span class="o">=</span>linux
                    kubernetes.io/arch<span class="o">=</span>amd64
                    kubernetes.io/hostname<span class="o">=</span>gitee-k8s-w29
                    kubernetes.io/os<span class="o">=</span>linux
Annotations:        io.cilium.network.ipv4-cilium-host: <span class="m">10</span>.0.24.248
                    io.cilium.network.ipv4-health-ip: <span class="m">10</span>.0.24.23
                    io.cilium.network.ipv4-pod-cidr: <span class="m">10</span>.0.24.0/24
                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: <span class="m">0</span>
                    volumes.kubernetes.io/controller-managed-attach-detach: <span class="nb">true</span>
CreationTimestamp:  Mon, <span class="m">18</span> Apr <span class="m">2022</span> <span class="m">11</span>:32:49 +0800

Taints:             <span class="nv">restart</span><span class="o">=</span>hourly:NoSchedule
</pre></div>
</div>
<p>除了自定义的污点之外，Kubernetes还会根据各个节点的当前运行情况，自动生成系统级的污点。</p>
<ul class="simple">
<li><p>node.Kubernetes.io/not-ready：节点还没有准备好，对应节点状态的Ready值为False。</p></li>
<li><p>node.Kubernetes.io/unreachable：节点控制器无法访问节点，对应节点状态的Ready值为Unknown。</p></li>
<li><p>node.Kubernetes.io/out-of-disk：节点磁盘空间不足。</p></li>
<li><p>node.Kubernetes.io/memory-pressure：节点存在内存压力。</p></li>
<li><p>node.Kubernetes.io/disk-pressure：节点磁盘存在压力。</p></li>
<li><p>node.Kubernetes.io/network-unavailable：节点网络不可用。</p></li>
<li><p>node.Kubernetes.io/unschedulable：节点不可被调度。</p></li>
<li><p>node.cloudprovider.Kubernetes.io/uninitialized：节点还未初始化完毕。</p></li>
</ul>
<p>在接下来的示例中，各个节点的污点配置如下所示。</p>
<p>其中，k8snode2有每小时重启的不稳定状况，所以不将Pod调度到该机器上；</p>
<p>k8snode3处于开机维护状态，也不将Pod调度到该机器上；</p>
<p>k8snode4的硬盘非常差，不推荐将Pod调度到该机器上。</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 7%" />
<col style="width: 27%" />
<col style="width: 27%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>k8
sno
de1</p></th>
<th class="head"><p>k8snode2</p></th>
<th class="head"><p>k8snode3</p></th>
<th class="head"><p>k8snode4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>无
污
点</p></td>
<td><p>restart=h
ourly:NoSchedule</p></td>
<td><p>isMaintai
n=true:NoExecute</p></td>
<td><p>diskSpeed=v
erySlow:PreferNoSchedule</p></td>
</tr>
</tbody>
</table>
<p>如果此时定义一个任意的Pod，其调度过程将如下图所示。</p>
<p>k8snode2和k8snode3因为存在污点，所以在预选阶段就会被筛除。</p>
<p><strong>然后对k8snode1和k8snode4进行优先级选择，由于k8snode4存在不推荐的污点，因此k8snode1将获得最高优先级，</strong>
<strong>Pod调度到k8snode1上的概率更大。</strong></p>
<p>调度过程</p>
<img alt="../../_images/image-20220420105332814.png" src="../../_images/image-20220420105332814.png" />
</section>
<section id="id13">
<h3><a class="toc-backref" href="#id27">5.2 容忍</a><a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>创建设置了容忍度的Pod模板。</p>
<p><code class="docutils literal notranslate"><span class="pre">examplefortolerations.yml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">examplefortolerations</span>
<span class="nt">spec</span><span class="p">:</span>
  <span class="nt">containers</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">IfNotPresent</span>
  <span class="nt">tolerations</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="s">&quot;restart&quot;</span>
    <span class="nt">operator</span><span class="p">:</span> <span class="s">&quot;Equal&quot;</span>
    <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;hourly&quot;</span>
    <span class="nt">effect</span><span class="p">:</span> <span class="s">&quot;NoSchedule&quot;</span>
  <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="s">&quot;isMaintain&quot;</span>
    <span class="nt">operator</span><span class="p">:</span> <span class="s">&quot;Equal&quot;</span>
    <span class="nt">value</span><span class="p">:</span> <span class="s">&quot;true&quot;</span>
    <span class="nt">effect</span><span class="p">:</span> <span class="s">&quot;NoExecute&quot;</span>
    <span class="nt">tolerationSeconds</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3600</span>
</pre></div>
</div>
<p>这里tolerations定义了两个容忍度。</p>
<p>第一个容忍的污点为restart，operator为Equal，value为hourly，effect为NoSchedule。</p>
<p>这表示可以容忍restart等于hourly且影响为NoSchedule的污点。</p>
<p>第二个污点的定义与此类似，但增加了一个tolerationSeconds属性，表示可以容忍污点3600s。</p>
<p>如果Pod调度到了k8snode3上，由于它对isMaintain=true:NoExecute污点的容忍度为3600s，假设超过这个时间k8snode3还处于维护状态，没有清除该污点，则Pod会被驱逐。</p>
<p>应用该模板创建Pod后，其调度过程如下图所示。因为已容忍k8snode2和k8snode3上的污点，所以在预选阶段Pod不会被筛除。</p>
<p>由于k8snode1不存在污点，因此k8snode1将获得最高优先级，Pod调度到k8snode1上的概率更大。</p>
<p>调度过程</p>
<img alt="../../_images/image-20220420105748771.png" src="../../_images/image-20220420105748771.png" />
<p><strong>容忍度设置一般用于DaemonSet控制器，因为DaemonSet控制器下的应用通常是为节点本身提供服务的。</strong></p>
<p><strong>另外，在创建DaemonSet控制器时，还会自动为DeamonSet控制器的Pod添加以下容忍度，以防止DaemonSet控制器被破坏。</strong></p>
<ul class="simple">
<li><p>node.Kubernetes.io/unreachable:NoExecute</p></li>
<li><p>node.Kubernetes.io/not-ready:NoExecute</p></li>
<li><p>node.Kubernetes.io/memory-pressure:NoSchedule</p></li>
<li><p>node.Kubernetes.io/disk-pressure:NoSchedule</p></li>
<li><p>node.Kubernetes.io/out-of-disk:NoSchedule</p></li>
<li><p>node.Kubernetes.io/unschedulable:NoSchedule</p></li>
<li><p>node.Kubernetes.io/network-unavailable:NoSchedule</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="3.%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-%E6%A0%87%E7%AD%BE%E3%80%81%E9%80%89%E6%8B%A9%E5%99%A8%E5%8F%8A%E6%B3%A8%E8%A7%A3.html" class="btn btn-neutral float-left" title="资源管理-标签、选择器及注解" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="5.%E4%BC%98%E5%85%88%E7%BA%A7%E4%B8%8E%E6%8A%A2%E5%8D%A0%E5%BC%8F%E8%B0%83%E5%BA%A6.html" class="btn btn-neutral float-right" title="优先级与抢占式调度" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, huxiaojian.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>