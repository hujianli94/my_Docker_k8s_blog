# 通过Kubeadm部署kubernetes

公司大部分线下测试环境均采用Kubeadm安装，这也是目前官方默认的安装方式，比二进制安装方式更加简单，可以让初学者快速上手并测试。目前GitHub上也有很多基于Ansible的自动化安装方式，但是为了更好地学习Kubernetes，还是建议体验一下Kubernetes的手动安装过程，以熟悉Kubernetes的各个组件。

## 基本环境配置



| 主机名     | IP地址        | 说明       |
| ---------- | ------------- | ---------- |
| k8s-master | 172.16.60.236 | k8s-master |
| k8s-node1  | 172.16.60.178 | k8s-node1  |
| k8s-node2  | 172.16.60.226 | k8s-node2  |
| k8s-node3  | 172.16.60.9   | k8s-node3  |





## 部署步骤

> 以下不做特殊说明默认所有机子都执行



### 准备工作

各节点通信采用主机名的方式，这种方式与IP地址相比较更具有扩展性。以下介绍具体的安装步骤。所有节点配置hosts，修改/etc/hosts如下：

```shell
# 更新系统和软件包
yum update

# 设置主机名(master node 名字分开)
hostnamectl set-hostname k8s-master

# 同步时间
systemctl restart chronyd

# 添加host
# 以下ip是所有机器的内网ip
cat >> /etc/hosts <<'EOF'
172.16.60.236	k8s-master
172.16.60.178	k8s-node1 
172.16.60.226	k8s-node2 
172.16.60.9		k8s-node3 
EOF

cat >>/etc/resolv.conf <<'EOF'
nameserver 8.8.8.8
EOF

# 设置所有机器间无密码访问
ssh-keygen -t rsa
for i in k8s-master k8s-node1 k8s-node2 k8s-node3;do ssh-copy-id -i /root/.ssh/id_rsa.pub $i;done


# 关闭防火墙和iptables
systemctl stop firewalld.service
systemctl disable firewalld.service
systemctl stop iptables.service
systemctl disable iptables.service

# 关闭SELinux
setenforce 0
sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config

# 关闭swap
swapoff -a && sysctl -w vm.swappiness=0
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab 
```

注释swap挂载选项：

```shell
# grep "swap" /etc/fstab 
#UUID=a5ace1f8-ddcd-434d-afef-b5a73c7ef8e8 swap                    swap    defaults        0 0

```

所有节点同步时间。所有节点同步时间是必须的，并且需要加到开机自启动和计划任务中，如果节点时间不同步，会造成Etcd存储Kubernetes信息的键－值（key-value）数据库同步数据不正常，也会造成证书出现问题。时间同步配置如下：

```shell
yum -y install ntp
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 
echo "Asia/Shanghai" > /etc/timezone
ntpdate time2.aliyun.com
# 加入计划任务
crontab -l
*/5 * * * * ntpdate time2.aliyun.com

# 加入开机自启动
cat /etc/rc.local 
ntpdate time2.aliyun.com


# 将桥接的IPv4流量传递到iptables的链
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system  # 生效
```



所有节点配置limit：

```
ulimit -SHn 65535
```

所有节点都配置国内仓库源

```shell
wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo

wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
```

### 加载 ipvs 内核模块

- 安装 IPVS 模块

```shell
yum -y install ipvsadm ipset sysstat conntrack libseccomp
```

- 设置开机加载配置文件

```shell
cat >>/etc/modules-load.d/ipvs.conf<<EOF
ip_vs_dh
ip_vs_ftp
ip_vs
ip_vs_lblc
ip_vs_lblcr
ip_vs_lc
ip_vs_nq
ip_vs_pe_sip
ip_vs_rr
ip_vs_sed
ip_vs_sh
ip_vs_wlc
ip_vs_wrr
nf_conntrack_ipv4
EOF
```

- 设置开机加载 IPVS 模块

```shell
# 设置开机加载内核模块
systemctl enable systemd-modules-load.service   

# 重启后检查 ipvs 模块是否加载
lsmod | grep -e ip_vs -e nf_conntrack_ipv4     
```

- 如果集群已经部署在了 iptables 模式下，可以通过下面命令修改，修改 mode 为 ipvs 重启集群即可。

```
kubectl edit -n kube-system configmap kube-proxy
```

### 安装docker

```shell
# master执行以下转到repo目录
cd /etc/yum.repos.d/

# master执行下载docker阿里云镜像
wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# master同步到其他服务器
[root@k8s-master yum.repos.d]# for i in k8s-master k8s-node1 k8s-node2 k8s-node3;do scp docker-ce.repo $i:/etc/yum.repos.d/;done
docker-ce.repo                                                                                                             100% 2640   162.5KB/s   00:00    
docker-ce.repo                                                                                                             100% 2640     3.5MB/s   00:00    
docker-ce.repo                                                                                                             100% 2640     3.7MB/s   00:00 


# 安装docker(各个都要装)
yum -y install docker-ce

# 修改配置
nano /usr/lib/systemd/system/docker.service

# master增加一行如下
ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT

# 配置阿里云镜像加速
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://25bxwt20.mirror.aliyuncs.com"]
}
EOF

# 重启docker
sudo systemctl daemon-reload
sudo systemctl restart docker
systemctl enable docker
systemctl restart docker
```

### 安装kubeadm, kubectl, kubelet

```shell
# master执行以下
cat >> /etc/yum.repos.d/kubernetes.repo <<'EOF'
[kubernetes]
name=Kubernetes	Repository
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
EOF

# master检查仓库
yum repolist
yum list all | grep "^kube"

# master执行安装
yum install kubeadm kubelet kubectl -y

# 检查安装
rpm -ql kubectl 
rpm -ql kubeadm

# master上把仓库拷贝过去
cd /etc/yum.repos.d/
for i in k8s-master k8s-node1 k8s-node2 k8s-node3;do scp  kubernetes.repo $i:/etc/yum.repos.d/


# 所有node安装kubelet kubeadm
yum install kubelet kubeadm -y

# master和node执行以下
systemctl enable kubelet.service

# master查看所需的镜像
kubeadm config images list

# 所有机器都执行以下的拉取镜像的操作
# 由于kubeadm依赖国外的k8s.gcr.io的镜像，国内被墙所以这边的解决方案是下载国内的镜像重新打tag的方式
cat > images_pull_k8s.sh <<'EOF'
#!/bin/bash
k8s_Version="v1.18.3"

images=(  
	# 下面的镜像应该去除"k8s.gcr.io/"的前缀
    kube-apiserver:${k8s_Version}
    kube-controller-manager:${k8s_Version}
    kube-scheduler:${k8s_Version}
    kube-proxy:${k8s_Version}
    pause:3.2
    etcd:3.4.3-0
    coredns:1.6.7
)
 
for imageName in ${images[@]} ; do
    docker pull mirrorgcrio/$imageName
    docker tag mirrorgcrio/$imageName k8s.gcr.io/$imageName
    docker rmi mirrorgcrio/$imageName
done
EOF

chmod 755 images_pull_k8s.sh
./images_pull_k8s.sh
```

或者直接手动拉取镜像

```shell
docker pull mirrorgcrio/kube-apiserver:v1.18.3
docker pull mirrorgcrio/kube-controller-manager:v1.18.3
docker pull mirrorgcrio/kube-scheduler:v1.18.3
docker pull mirrorgcrio/kube-proxy:v1.18.3
docker pull mirrorgcrio/pause:3.2
docker pull mirrorgcrio/etcd:3.4.3-0
docker pull mirrorgcrio/coredns:1.6.7
 
docker tag mirrorgcrio/kube-apiserver:v1.18.3 k8s.gcr.io/kube-apiserver:v1.18.3
docker tag mirrorgcrio/kube-controller-manager:v1.18.3 k8s.gcr.io/kube-controller-manager:v1.18.3
docker tag mirrorgcrio/kube-scheduler:v1.18.3 k8s.gcr.io/kube-scheduler:v1.18.3
docker tag mirrorgcrio/kube-proxy:v1.18.3 k8s.gcr.io/kube-proxy:v1.18.3
docker tag mirrorgcrio/pause:3.2 k8s.gcr.io/pause:3.2
docker tag mirrorgcrio/etcd:3.4.3-0 k8s.gcr.io/etcd:3.4.3-0
docker tag mirrorgcrio/coredns:1.6.7 k8s.gcr.io/coredns:1.6.7
 
docker image rm mirrorgcrio/kube-apiserver:v1.18.3
docker image rm mirrorgcrio/kube-controller-manager:v1.18.3
docker image rm mirrorgcrio/kube-scheduler:v1.18.3
docker image rm mirrorgcrio/kube-proxy:v1.18.3
docker image rm mirrorgcrio/pause:3.2
docker image rm mirrorgcrio/etcd:3.4.3-0
docker image rm mirrorgcrio/coredns:1.6.7
```

## Master初始化kubeadm

> 本小节的所有的操作，只在 Master 节点上进行

```shell
# master执行init初始化
kubeadm init \
--kubernetes-version="v1.18.3" \
--pod-network-cidr="10.244.0.0/16" \
--ignore-preflight-errors="NumCPU"

# 后续步骤
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 应用网络插件flannle
[root@k8s-master home]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

## node加入集群

```shell
[root@k8s-node1 home]# kubeadm join 172.16.60.236:6443 --token 950v9y.z3lz25askvjw33ou \
>     --discovery-token-ca-cert-hash sha256:e84f8923f43878b530c6d5879c258ccdd5caec1d02ee8d89d1d75b9bdf4d753e
......
Run 'kubectl get nodes' on the control-plane to see this node join the cluster
```

## 查看部署状态

```shell
# master查看node节点状态
kubectl get nodes

# master查看kube-system命名空间下的pod启动的状态
kubectl get po -n kube-system

# 如果有pod一直启动不起来，通过describe查看状态
kubectl describe po/{具体的pod名字} -n kube-system
```

## 参考文献

[kubeadm安装k8s 1.13版本](https://www.cnblogs.com/yangxiaochu/p/10683951.html)

[ubuntu18.04 kubeadm 安装kubernetes v1.18.3](<https://blog.csdn.net/happyworld1/article/details/106383464/>)

